{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download NLTK resources\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "import re\n",
    "import pandas as pd\n",
    "import emoji\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('final_dataset.csv')  \n",
    "\n",
    "# Before preprocessing\n",
    "df.to_csv('before_preprocessing.csv', index=False)\n",
    "\n",
    "# Define a dictionary mapping emoticons to emojis\n",
    "emoticon_to_emoji = {\n",
    "    ':)': '😊', ':D': '😃', ':]': '😃', ':(': '😞', ':/': '😕', ':|': '😐',\n",
    "    ':-)': '😊', ':-D': '😃', ';)': '😉', ':\\'(': '😢', ':-/': '😕', ':-|': '😐',\n",
    "    ':-P': '😜', ':-O': '😲', ':O': '😲', ':*': '😘', '<3': '❤️', ':-$': '🤑',\n",
    "    ':-!': '😤', ':-(': '😞', ':-[': '😟', ':-@': '😠', ':-#': '🤐', ':-*': '😗',\n",
    "    ':^)': '😊', '8-)': '😎', '>:(': '😡', ':-\\\\': '😕', ':-/': '😕', ':-&': '😤',\n",
    "    'O:-)': '😇', ':-X': '🤐', ':-D': '😃', '=)': '😊', '=D': '😃', '<3': '❤️',\n",
    "    'XD': '😆', ':-D': '😃', '=D': '😃', ':-]': '😃', ':->': '😃', ':-o': '😲',\n",
    "    ';-)': '😉', '(-:': '😃', '(-_-)': '😑', ':-]': '😃', ':->': '😃', '<3': '❤️',\n",
    "    '=]': '😃', ':3': '😺', ':c)': '😺', ':>': '😃', '=]': '😃', ':}': '😃',\n",
    "    '8-)': '😎', 'B-)': '😎', '8-D': '😃', '>:D': '😡', 'X-D': '😆', 'x-D': '😆',\n",
    "    'X)': '😆', 'x)': '😆', 'X3': '😺', 'x3': '😺', ':-Q': '😖', '=p': '😛',\n",
    "    ':-j': '😒', ':-L': '😒', ':-)': '😊', ':-D': '😃', ':-(': '😞', ':-[': '😟',\n",
    "    ':-@': '😠', ':-#': '🤐', ':-*': '😗', 'O:-)': '😇', ':-X': '🤐', ':-D': '😃',\n",
    "    '=)': '😊', '=D': '😃', '<3': '❤️', 'XD': '😆', ':-D': '😃', '=D': '😃',\n",
    "    ':-]': '😃', ':->': '😃', ':-o': '😲', ';-)': '😉', '(-:': '😃', '(-_-)': '😑',\n",
    "    ':-]': '😃', ':->': '😃', '<3': '❤️', '=]': '😃', ':3': '😺', ':c)': '😺',\n",
    "    ':>': '😃', '=]': '😃', ':}': '😃', '8-)': '😎', 'B-)': '😎', '8-D': '😃',\n",
    "    '>:D': '😡', 'X-D': '😆', 'x-D': '😆', 'X)': '😆', 'x)': '😆', 'X3': '😺',\n",
    "    'x3': '😺', ':-Q': '😖', '=p': '😛', ':-j': '😒', ':-L': '😒', ':-|': '😐',\n",
    "    '=\\\\': '😕', ':-&': '😤', 'O:-)': '😇', ':-X': '🤐', ':-D': '😃', '=)': '😊',\n",
    "    '=D': '😃', '<3': '❤️', 'XD': '😆', ':-D': '😃', '=D': '😃', ':-]': '😃',\n",
    "    ':->': '😃', ':-o': '😲', ';-)': '😉'}\n",
    "\n",
    "# Function to replace emoticons with emojis in a given text\n",
    "def replace_emoticons_with_emojis(text):\n",
    "    for emoticon, emoji in emoticon_to_emoji.items():\n",
    "        text = text.replace(emoticon, emoji)\n",
    "    return text\n",
    "\n",
    "# Apply the function to the 'body' column\n",
    "df['body'] = df['body'].apply(replace_emoticons_with_emojis)\n",
    "\n",
    "# Add a space between emojis in the 'body' column\n",
    "df['body'] = df['body'].apply(lambda x: re.sub(r'(:[^\\s:]+:)', r'\\1 ', x))\n",
    "\n",
    "# Apply demojize directly to the 'body' column\n",
    "df['body'] = df['body'].apply(emoji.demojize)\n",
    "\n",
    "# Remove colons and replace underscores in df['body']\n",
    "df['body'] = df['body'].apply(lambda x: x.replace(':', '').replace('_', ' '))\n",
    "\n",
    "\n",
    "# Sentiment slang dictionary for Canadian terms with meanings\n",
    "sentiment_slang_dict = {\n",
    "    'omg':'Oh my God',\n",
    "    'beauty, eh': 'excellent, right?',\n",
    "    'all smiles': 'very happy',\n",
    "    'pumped': 'excited',\n",
    "    'over the moon': 'extremely happy',\n",
    "    'hot under the collar': 'angry',\n",
    "    'pissed off': 'very angry',\n",
    "    'bent out of shape': 'upset',\n",
    "    'seeing red': 'becoming very angry',\n",
    "    'rough day, eh?': 'difficult day, right?',\n",
    "    'not impressed': 'unimpressed',\n",
    "    'down in the dumps': 'feeling sad',\n",
    "    'going through a rough patch': 'experiencing a difficult time',\n",
    "    'fed up': 'frustrated or annoyed',\n",
    "}\n",
    "\n",
    "# Apply sentiment handling to the DataFrame\n",
    "df['body'] = df['body'].apply(lambda x: ' '.join([sentiment_slang_dict[token] if token in sentiment_slang_dict else token for token in x.split()]))\n",
    "\n",
    "# Lowercasing\n",
    "df['body'] = df['body'].apply(lambda x: x.lower())\n",
    "\n",
    "# Retain certain characters like '@' and '_'\n",
    "df['body'] = df['body'].apply(lambda x: re.sub(r'[^A-Za-z0-9@_ ]', '', x))\n",
    "\n",
    "# Replace hashtags with a space in df['body']\n",
    "df['body'] = df['body'].apply(lambda x: re.sub(r'#', ' ', x))\n",
    "\n",
    "# Tokenization\n",
    "df['tokens'] = df['body'].apply(word_tokenize)\n",
    "\n",
    "# Stop-word removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [token for token in x if token.lower() not in stop_words])\n",
    "\n",
    "# Stemming\n",
    "ps = PorterStemmer()\n",
    "df['stemmed_tokens'] = df['tokens'].apply(lambda x: [ps.stem(token) for token in x])\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['lemmatized_tokens'] = df['tokens'].apply(lambda x: [lemmatizer.lemmatize(token) for token in x])\n",
    "\n",
    "# Save the preprocessed DataFrame to a new CSV file preprocessed_output.csv\n",
    "df.to_csv('preprocessed_output.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6908, 7)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['body', 'score', 'comment_length', 'predicted_sentiment', 'tokens',\n",
       "       'stemmed_tokens', 'lemmatized_tokens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                body\n",
      "0  :disappointed_face: I feel :(, I hate the poli...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import emoji\n",
    "\n",
    "data = {'body': [\"😞 I feel :(, I hate the politics in my country \"]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply demojize directly to the 'body' column\n",
    "df['body'] = df['body'].apply(emoji.demojize)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      body\n",
      "0  I hate the politics in my country 😕😕😕😕.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import emoji\n",
    "\n",
    "# Sample DataFrame creation\n",
    "data = {'body': [\"I hate the politics in my country :/:/:/:/.\"]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define a dictionary mapping emoticons to emojis\n",
    "emoticon_to_emoji = {\n",
    "    ':)': '😊', ':D': '😃', ':]': '😃', ':(': '😞', ':/': '😕', ':|': '😐'\n",
    "}\n",
    "\n",
    "# Function to replace emoticons with emojis in a given text\n",
    "def replace_emoticons_with_emojis(text):\n",
    "    for emoticon, emoji in emoticon_to_emoji.items():\n",
    "        text = text.replace(emoticon, emoji)\n",
    "    return text\n",
    "\n",
    "# Apply the function to the 'body' column\n",
    "df['body'] = df['body'].apply(replace_emoticons_with_emojis)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
